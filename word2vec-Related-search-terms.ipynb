{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7W-KgJ5H8K4"
      },
      "outputs": [],
      "source": [
        "# word 2 vec 을 사용해 벡터라이즈, 단어의 맥락을 유지함,\n",
        "#유클리디안거리,코사인유사도 방식으로 거리를 측정하고 거리가 가까울 수록 의미가 비슷하다"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub5AO2j4IB1x",
        "outputId": "c1f9a0cf-0334-4c84-f5e3-b42931ade0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\"\"\"\n",
        "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며\n",
        "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
        "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
        "\"\"\"\n",
        "\n",
        "# 레이블인 sentiment 가 있는 학습 데이터\n",
        "train = pd.read_csv('https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/data/labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
        "# 레이블이 없는 테스트 데이터\n",
        "test = pd.read_csv('https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/data/testData.tsv', delimiter='\\t', quoting=3)\n",
        "\n",
        "unlabeled_train = pd.read_csv('https://github.com/corazzon/KaggleStruggle/raw/master/word2vec-nlp-tutorial/data/unlabeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
        "\n",
        "train.shape, test.shape, unlabeled_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXDN8Q4HIB8x",
        "outputId": "0ab62f13-067a-4abe-e0d7-8ff79b0773ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 3), (25000, 2), (50000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled_train.head() # 긍정부정이 없음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "veTbr5eGICBb",
        "outputId": "0f387c06-e597-488d-8494-3c81b94ea610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-162e3686-e78e-4cd3-90df-6f1c6e5caba4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-162e3686-e78e-4cd3-90df-6f1c6e5caba4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-162e3686-e78e-4cd3-90df-6f1c6e5caba4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-162e3686-e78e-4cd3-90df-6f1c6e5caba4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          id                                             review\n",
              "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
              "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
              "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
              "3   \"7161_0\"  \"I went to see this film with a great deal of ...\n",
              "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lpqukUSdICGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from multiprocessing import Pool\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "def review_to_words( raw_review, remove_stopwords=False ):\n",
        "    # 1. HTML 제거\n",
        "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
        "    # 2. 영문자가 아닌 문자는 공백으로 변환\n",
        "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "    # 3. 소문자 변환\n",
        "    words = letters_only.lower().split()\n",
        "    if remove_stopwords:\n",
        "      stops = set(stopwords.words('english'))\n",
        "      words = [w for w in words if not w in stops]\n",
        "\n",
        "    stemmer = nltk.stem.SnowballStemmer('english') # 형태소 분석기 포터스태머\n",
        "    # 6. 어간추출\n",
        "    words = [stemmer.stem(w) for w in words]\n",
        "    return( words )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCE3eKk2ICKk",
        "outputId": "23445cba-6aab-45c1-fb47-75fde1672411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "class KaggleWord2VecUtility(object):\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_wordlist(review, remove_stopwords=False):\n",
        "        # 1. HTML 제거\n",
        "        review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
        "        # 2. 특수문자를 공백으로 바꿔줌\n",
        "        review_text = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "        # 3. 소문자로 변환 후 나눈다.\n",
        "        words = review_text.lower().split()\n",
        "        # 4. 불용어 제거\n",
        "        if remove_stopwords:\n",
        "            stops = set(stopwords.words('english'))\n",
        "            words = [w for w in words if not w in stops]\n",
        "        # 5. 어간추출\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        words = [stemmer.stem(w) for w in words]\n",
        "        # 6. 리스트 형태로 반환\n",
        "        return(words)\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_join_words( review, remove_stopwords=False ):\n",
        "        words = KaggleWord2VecUtility.review_to_wordlist(\\\n",
        "            review, remove_stopwords=False)\n",
        "        join_words = ' '.join(words)\n",
        "        return join_words\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_sentences( review, remove_stopwords=False ):\n",
        "        # punkt tokenizer를 로드한다.\n",
        "        \"\"\"\n",
        "        이 때, pickle을 사용하는데\n",
        "        pickle을 통해 값을 저장하면 원래 변수에 연결 된 참조값 역시 저장된다.\n",
        "        저장된 pickle을 다시 읽으면 변수에 연결되었던\n",
        "        모든 레퍼런스가 계속 참조 상태를 유지한다.\n",
        "        \"\"\"\n",
        "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "        # 1. nltk tokenizer를 사용해서 단어로 토큰화 하고 공백 등을 제거한다.\n",
        "        raw_sentences = tokenizer.tokenize(review.strip())\n",
        "        # 2. 각 문장을 순회한다.\n",
        "        sentences = []\n",
        "        for raw_sentence in raw_sentences:\n",
        "            # 비어있다면 skip\n",
        "            if len(raw_sentence) > 0:\n",
        "                # 태그제거, 알파벳문자가 아닌 것은 공백으로 치환, 불용어제거\n",
        "                sentences.append(\\\n",
        "                    KaggleWord2VecUtility.review_to_wordlist(\\\n",
        "                    raw_sentence, remove_stopwords))\n",
        "        return sentences\n",
        "\n",
        "\n",
        "    # 참고 : https://gist.github.com/yong27/7869662\n",
        "    # http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
        "    # 속도 개선을 위해 멀티 스레드로 작업하도록\n",
        "    @staticmethod\n",
        "    def _apply_df(args):\n",
        "        df, func, kwargs = args\n",
        "        return df.apply(func, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_by_multiprocessing(df, func, **kwargs):\n",
        "        # 키워드 항목 중 workers 파라메터를 꺼냄\n",
        "        workers = kwargs.pop('workers')\n",
        "        # 위에서 가져온 workers 수로 프로세스 풀을 정의\n",
        "        pool = Pool(processes=workers)\n",
        "        # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n",
        "        result = pool.map(KaggleWord2VecUtility._apply_df, [(d, func, kwargs)\n",
        "                for d in np.array_split(df, workers)])\n",
        "        pool.close()\n",
        "        # 작업 결과를 합쳐서 반환\n",
        "        return pd.concat(result)"
      ],
      "metadata": {
        "id": "4nAUl7-ibGol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(review_to_words(train['review'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJWSzSzHPWnj",
        "outputId": "58d4d180-557e-4885-88fd-23949dea16f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "437"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['review']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buaE8R1WWDqz",
        "outputId": "b78aa23d-466e-442e-d305-848fec4ca775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        \"With all this stuff going down at the moment ...\n",
              "1        \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2        \"The film starts with a manager (Nicholas Bell...\n",
              "3        \"It must be assumed that those who praised thi...\n",
              "4        \"Superbly trashy and wondrously unpretentious ...\n",
              "                               ...                        \n",
              "24995    \"It seems like more consideration has gone int...\n",
              "24996    \"I don't believe they made this film. Complete...\n",
              "24997    \"Guy is a loser. Can't get girls, needs to bui...\n",
              "24998    \"This 30 minute documentary Buñuel made in the...\n",
              "24999    \"I saw this movie as a child and it broke my h...\n",
              "Name: review, Length: 25000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배열 담기"
      ],
      "metadata": {
        "id": "bphsZI2TOCQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "sentences = []\n",
        "for review in train[\"review\"]:\n",
        "    sentences += KaggleWord2VecUtility.review_to_sentences(\n",
        "        review, remove_stopwords=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7vmjZUSOcoY",
        "outputId": "088e061c-360d-4270-99f5-072cd80831e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.happierabroad.com\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HArGcLWLbFmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in unlabeled_train[\"review\"]:\n",
        "    sentences += KaggleWord2VecUtility.review_to_sentences(\n",
        "        review, remove_stopwords=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKrMqo2FOcrz",
        "outputId": "e8c42e80-0463-47d5-b832-37f81600f2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:273: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ8pySHyOcye",
        "outputId": "ed40dc13-a530-4953-fa4b-52fed8d1804c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "795538"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFv79co8PEwV",
        "outputId": "a9e90d34-4159-4cfe-b36a-d6dd8653b1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with', 'all', 'this', 'stuff', 'go', 'down', 'at', 'the', 'moment', 'with']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[1][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1pR8TtHTJmp",
        "outputId": "f3a3e42b-7172-49da-8c51-1b02a16c17d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mayb', 'i', 'just', 'want', 'to', 'get', 'a', 'certain', 'insight', 'into']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kIg3O7T8Vxsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s : %(levelname)s : %(message)s',\n",
        "    level=logging.INFO)"
      ],
      "metadata": {
        "id": "aFF3NhX1OCU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec 모델의 파라메터\n",
        "# 아키텍처 : 아키텍처 옵션은 skip-gram (default) 또는 CBOW 모델이다. skip-gram (default)은 느리지 만 더 나은 결과를 낸다.\n",
        "\n",
        "# 학습 알고리즘 : Hierarchical softmax (default) 또는 negative 샘플링. 여기에서는 기본값이 잘 동작한다.\n",
        "\n",
        "# 빈번하게 등장하는 단어에 대한 다운 샘플링 : Google 문서는 .00001에서 .001 사이의 값을 권장한다. 여기에서는 0.001에 가까운 값이 최종 모델의 정확도를 높이는 것으로 보여진다.\n",
        "\n",
        "# 단어 벡터 차원 : 많은 feature를 사용한다고 항상 좋은 것은 아니지만 대체적으로 좀 더 나은 모델이 된다. 합리적인 값은 수십에서 수백 개가 될 수 있고 여기에서는 300으로 지정했다.\n",
        "\n",
        "# 컨텍스트 / 창 크기 : 학습 알고리즘이 고려해야하는 컨텍스트의 단어 수는 얼마나 될까? hierarchical softmax 를 위해 좀 더 큰 수가 좋지만 10 정도가 적당하다.\n",
        "\n",
        "# Worker threads : 실행할 병렬 프로세스의 수로 컴퓨터마다 다르지만 대부분의 시스템에서 4에서 6 사이의 값을 사용하다.\n",
        "\n",
        "# 최소 단어 수 : 어휘의 크기를 의미있는 단어로 제한하는 데 도움이 된다. 모든 문서에서이 여러 번 발생하지 않는 단어는 무시된다. 10에서 100 사이가 적당하며, 이 경진대회의 데이터는 각 영화가 30개씩의 리뷰가 있기 때문에 개별 영화 제목에 너무 많은 중요성이 붙는 것을 피하기 위해 최소 단어 수를 40으로 설정한다. 그 결과 전체 어휘 크기는 약 15,000 단어가 된다. 높은 값은 제한 된 실행시간에 도움이 된다."
      ],
      "metadata": {
        "id": "H7TutMe6R91d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라메터값 지정\n",
        "num_features = 300 # 문자 벡터 차원 수\n",
        "min_word_count = 40 # 최소 문자 수\n",
        "num_workers = 4 # 병렬 처리 스레드 수\n",
        "context = 10 # 문자열 창 크기\n",
        "downsampling = 1e-3 # 문자 빈도 수 Downsample\n",
        "\n",
        "# 초기화 및 모델 학습\n",
        "from gensim.models import word2vec\n",
        "\n",
        "# 모델 학습\n",
        "model = word2vec.Word2Vec(sentences,\n",
        "                          workers=num_workers,\n",
        "                          size=num_features,\n",
        "                          min_count=min_word_count,\n",
        "                          window=context,\n",
        "                          sample=downsampling)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1VngQtcOCXT",
        "outputId": "8d2a379b-73ad-466b-e2d6-6d7dc792a21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 12:20:59,488 : INFO : collecting all words and their counts\n",
            "2022-01-27 12:20:59,494 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-01-27 12:20:59,682 : INFO : PROGRESS: at sentence #10000, processed 225803 words, keeping 12465 word types\n",
            "2022-01-27 12:20:59,897 : INFO : PROGRESS: at sentence #20000, processed 451892 words, keeping 17070 word types\n",
            "2022-01-27 12:21:00,128 : INFO : PROGRESS: at sentence #30000, processed 671314 words, keeping 20370 word types\n",
            "2022-01-27 12:21:00,249 : INFO : PROGRESS: at sentence #40000, processed 897814 words, keeping 23125 word types\n",
            "2022-01-27 12:21:00,480 : INFO : PROGRESS: at sentence #50000, processed 1116962 words, keeping 25365 word types\n",
            "2022-01-27 12:21:00,689 : INFO : PROGRESS: at sentence #60000, processed 1338403 words, keeping 27283 word types\n",
            "2022-01-27 12:21:00,820 : INFO : PROGRESS: at sentence #70000, processed 1561579 words, keeping 29024 word types\n",
            "2022-01-27 12:21:00,932 : INFO : PROGRESS: at sentence #80000, processed 1780886 words, keeping 30603 word types\n",
            "2022-01-27 12:21:01,068 : INFO : PROGRESS: at sentence #90000, processed 2004995 words, keeping 32223 word types\n",
            "2022-01-27 12:21:01,210 : INFO : PROGRESS: at sentence #100000, processed 2226966 words, keeping 33579 word types\n",
            "2022-01-27 12:21:01,311 : INFO : PROGRESS: at sentence #110000, processed 2446580 words, keeping 34827 word types\n",
            "2022-01-27 12:21:01,581 : INFO : PROGRESS: at sentence #120000, processed 2668775 words, keeping 36183 word types\n",
            "2022-01-27 12:21:01,887 : INFO : PROGRESS: at sentence #130000, processed 2894303 words, keeping 37353 word types\n",
            "2022-01-27 12:21:02,197 : INFO : PROGRESS: at sentence #140000, processed 3107005 words, keeping 38376 word types\n",
            "2022-01-27 12:21:02,492 : INFO : PROGRESS: at sentence #150000, processed 3332627 words, keeping 39556 word types\n",
            "2022-01-27 12:21:02,696 : INFO : PROGRESS: at sentence #160000, processed 3555315 words, keeping 40629 word types\n",
            "2022-01-27 12:21:02,893 : INFO : PROGRESS: at sentence #170000, processed 3778655 words, keeping 41628 word types\n",
            "2022-01-27 12:21:03,026 : INFO : PROGRESS: at sentence #180000, processed 3999236 words, keeping 42599 word types\n",
            "2022-01-27 12:21:03,140 : INFO : PROGRESS: at sentence #190000, processed 4224449 words, keeping 43461 word types\n",
            "2022-01-27 12:21:03,289 : INFO : PROGRESS: at sentence #200000, processed 4448603 words, keeping 44301 word types\n",
            "2022-01-27 12:21:03,456 : INFO : PROGRESS: at sentence #210000, processed 4669967 words, keeping 45212 word types\n",
            "2022-01-27 12:21:03,612 : INFO : PROGRESS: at sentence #220000, processed 4894968 words, keeping 46134 word types\n",
            "2022-01-27 12:21:03,727 : INFO : PROGRESS: at sentence #230000, processed 5117546 words, keeping 46986 word types\n",
            "2022-01-27 12:21:03,843 : INFO : PROGRESS: at sentence #240000, processed 5345051 words, keeping 47854 word types\n",
            "2022-01-27 12:21:03,981 : INFO : PROGRESS: at sentence #250000, processed 5559166 words, keeping 48699 word types\n",
            "2022-01-27 12:21:04,084 : INFO : PROGRESS: at sentence #260000, processed 5779147 words, keeping 49469 word types\n",
            "2022-01-27 12:21:04,256 : INFO : PROGRESS: at sentence #270000, processed 6000436 words, keeping 50416 word types\n",
            "2022-01-27 12:21:04,375 : INFO : PROGRESS: at sentence #280000, processed 6226315 words, keeping 51640 word types\n",
            "2022-01-27 12:21:04,543 : INFO : PROGRESS: at sentence #290000, processed 6449475 words, keeping 52754 word types\n",
            "2022-01-27 12:21:04,721 : INFO : PROGRESS: at sentence #300000, processed 6674078 words, keeping 53755 word types\n",
            "2022-01-27 12:21:04,841 : INFO : PROGRESS: at sentence #310000, processed 6899392 words, keeping 54734 word types\n",
            "2022-01-27 12:21:04,970 : INFO : PROGRESS: at sentence #320000, processed 7124279 words, keeping 55770 word types\n",
            "2022-01-27 12:21:05,105 : INFO : PROGRESS: at sentence #330000, processed 7346022 words, keeping 56687 word types\n",
            "2022-01-27 12:21:05,240 : INFO : PROGRESS: at sentence #340000, processed 7575534 words, keeping 57629 word types\n",
            "2022-01-27 12:21:05,326 : INFO : PROGRESS: at sentence #350000, processed 7798804 words, keeping 58485 word types\n",
            "2022-01-27 12:21:05,388 : INFO : PROGRESS: at sentence #360000, processed 8019467 words, keeping 59345 word types\n",
            "2022-01-27 12:21:05,454 : INFO : PROGRESS: at sentence #370000, processed 8246659 words, keeping 60161 word types\n",
            "2022-01-27 12:21:05,514 : INFO : PROGRESS: at sentence #380000, processed 8471806 words, keeping 61069 word types\n",
            "2022-01-27 12:21:05,577 : INFO : PROGRESS: at sentence #390000, processed 8701556 words, keeping 61810 word types\n",
            "2022-01-27 12:21:05,637 : INFO : PROGRESS: at sentence #400000, processed 8924505 words, keeping 62546 word types\n",
            "2022-01-27 12:21:05,701 : INFO : PROGRESS: at sentence #410000, processed 9145855 words, keeping 63263 word types\n",
            "2022-01-27 12:21:05,763 : INFO : PROGRESS: at sentence #420000, processed 9366935 words, keeping 64024 word types\n",
            "2022-01-27 12:21:05,829 : INFO : PROGRESS: at sentence #430000, processed 9594472 words, keeping 64795 word types\n",
            "2022-01-27 12:21:05,892 : INFO : PROGRESS: at sentence #440000, processed 9821225 words, keeping 65539 word types\n",
            "2022-01-27 12:21:05,952 : INFO : PROGRESS: at sentence #450000, processed 10044987 words, keeping 66378 word types\n",
            "2022-01-27 12:21:06,016 : INFO : PROGRESS: at sentence #460000, processed 10277747 words, keeping 67158 word types\n",
            "2022-01-27 12:21:06,084 : INFO : PROGRESS: at sentence #470000, processed 10505672 words, keeping 67775 word types\n",
            "2022-01-27 12:21:06,146 : INFO : PROGRESS: at sentence #480000, processed 10726056 words, keeping 68500 word types\n",
            "2022-01-27 12:21:06,211 : INFO : PROGRESS: at sentence #490000, processed 10952800 words, keeping 69256 word types\n",
            "2022-01-27 12:21:06,271 : INFO : PROGRESS: at sentence #500000, processed 11174456 words, keeping 69892 word types\n",
            "2022-01-27 12:21:06,345 : INFO : PROGRESS: at sentence #510000, processed 11399731 words, keeping 70593 word types\n",
            "2022-01-27 12:21:06,412 : INFO : PROGRESS: at sentence #520000, processed 11623082 words, keeping 71267 word types\n",
            "2022-01-27 12:21:06,474 : INFO : PROGRESS: at sentence #530000, processed 11847480 words, keeping 71877 word types\n",
            "2022-01-27 12:21:06,536 : INFO : PROGRESS: at sentence #540000, processed 12072095 words, keeping 72537 word types\n",
            "2022-01-27 12:21:06,598 : INFO : PROGRESS: at sentence #550000, processed 12297646 words, keeping 73212 word types\n",
            "2022-01-27 12:21:06,660 : INFO : PROGRESS: at sentence #560000, processed 12518936 words, keeping 73861 word types\n",
            "2022-01-27 12:21:06,734 : INFO : PROGRESS: at sentence #570000, processed 12748083 words, keeping 74431 word types\n",
            "2022-01-27 12:21:06,803 : INFO : PROGRESS: at sentence #580000, processed 12969579 words, keeping 75087 word types\n",
            "2022-01-27 12:21:06,866 : INFO : PROGRESS: at sentence #590000, processed 13195103 words, keeping 75734 word types\n",
            "2022-01-27 12:21:06,927 : INFO : PROGRESS: at sentence #600000, processed 13417301 words, keeping 76295 word types\n",
            "2022-01-27 12:21:06,991 : INFO : PROGRESS: at sentence #610000, processed 13638324 words, keeping 76953 word types\n",
            "2022-01-27 12:21:07,056 : INFO : PROGRESS: at sentence #620000, processed 13864649 words, keeping 77504 word types\n",
            "2022-01-27 12:21:07,118 : INFO : PROGRESS: at sentence #630000, processed 14088935 words, keeping 78067 word types\n",
            "2022-01-27 12:21:07,180 : INFO : PROGRESS: at sentence #640000, processed 14309718 words, keeping 78693 word types\n",
            "2022-01-27 12:21:07,243 : INFO : PROGRESS: at sentence #650000, processed 14535474 words, keeping 79296 word types\n",
            "2022-01-27 12:21:07,317 : INFO : PROGRESS: at sentence #660000, processed 14758264 words, keeping 79865 word types\n",
            "2022-01-27 12:21:07,382 : INFO : PROGRESS: at sentence #670000, processed 14981657 words, keeping 80382 word types\n",
            "2022-01-27 12:21:07,445 : INFO : PROGRESS: at sentence #680000, processed 15206489 words, keeping 80913 word types\n",
            "2022-01-27 12:21:07,505 : INFO : PROGRESS: at sentence #690000, processed 15428682 words, keeping 81483 word types\n",
            "2022-01-27 12:21:07,574 : INFO : PROGRESS: at sentence #700000, processed 15657388 words, keeping 82075 word types\n",
            "2022-01-27 12:21:07,635 : INFO : PROGRESS: at sentence #710000, processed 15880377 words, keeping 82561 word types\n",
            "2022-01-27 12:21:07,695 : INFO : PROGRESS: at sentence #720000, processed 16105664 words, keeping 83037 word types\n",
            "2022-01-27 12:21:07,756 : INFO : PROGRESS: at sentence #730000, processed 16332045 words, keeping 83572 word types\n",
            "2022-01-27 12:21:07,817 : INFO : PROGRESS: at sentence #740000, processed 16553078 words, keeping 84128 word types\n",
            "2022-01-27 12:21:07,882 : INFO : PROGRESS: at sentence #750000, processed 16771405 words, keeping 84600 word types\n",
            "2022-01-27 12:21:07,942 : INFO : PROGRESS: at sentence #760000, processed 16990809 words, keeping 85069 word types\n",
            "2022-01-27 12:21:08,003 : INFO : PROGRESS: at sentence #770000, processed 17217946 words, keeping 85645 word types\n",
            "2022-01-27 12:21:08,066 : INFO : PROGRESS: at sentence #780000, processed 17448092 words, keeping 86161 word types\n",
            "2022-01-27 12:21:08,127 : INFO : PROGRESS: at sentence #790000, processed 17675168 words, keeping 86666 word types\n",
            "2022-01-27 12:21:08,167 : INFO : collected 86997 word types from a corpus of 17798269 raw words and 795538 sentences\n",
            "2022-01-27 12:21:08,170 : INFO : Loading a fresh vocabulary\n",
            "2022-01-27 12:21:08,252 : INFO : effective_min_count=40 retains 11986 unique words (13% of original 86997, drops 75011)\n",
            "2022-01-27 12:21:08,254 : INFO : effective_min_count=40 leaves 17434031 word corpus (97% of original 17798269, drops 364238)\n",
            "2022-01-27 12:21:08,302 : INFO : deleting the raw counts dictionary of 86997 items\n",
            "2022-01-27 12:21:08,311 : INFO : sample=0.001 downsamples 50 most-common words\n",
            "2022-01-27 12:21:08,314 : INFO : downsampling leaves estimated 12872362 word corpus (73.8% of prior 17434031)\n",
            "2022-01-27 12:21:08,373 : INFO : estimated required memory for 11986 words and 300 dimensions: 34759400 bytes\n",
            "2022-01-27 12:21:08,375 : INFO : resetting layer weights\n",
            "2022-01-27 12:21:11,076 : INFO : training model with 4 workers on 11986 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
            "2022-01-27 12:21:12,111 : INFO : EPOCH 1 - PROGRESS: at 2.62% examples, 332297 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:21:13,120 : INFO : EPOCH 1 - PROGRESS: at 5.37% examples, 341613 words/s, in_qsize 7, out_qsize 1\n",
            "2022-01-27 12:21:14,125 : INFO : EPOCH 1 - PROGRESS: at 8.16% examples, 344700 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:21:15,175 : INFO : EPOCH 1 - PROGRESS: at 11.09% examples, 348073 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:16,194 : INFO : EPOCH 1 - PROGRESS: at 13.94% examples, 349422 words/s, in_qsize 4, out_qsize 3\n",
            "2022-01-27 12:21:17,196 : INFO : EPOCH 1 - PROGRESS: at 16.78% examples, 351198 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:18,204 : INFO : EPOCH 1 - PROGRESS: at 19.71% examples, 354235 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:21:19,221 : INFO : EPOCH 1 - PROGRESS: at 22.48% examples, 353413 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:20,227 : INFO : EPOCH 1 - PROGRESS: at 25.28% examples, 354022 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:21,251 : INFO : EPOCH 1 - PROGRESS: at 28.03% examples, 353137 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:22,258 : INFO : EPOCH 1 - PROGRESS: at 30.91% examples, 354253 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:21:23,270 : INFO : EPOCH 1 - PROGRESS: at 33.66% examples, 353228 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 12:21:24,302 : INFO : EPOCH 1 - PROGRESS: at 36.51% examples, 353515 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:25,304 : INFO : EPOCH 1 - PROGRESS: at 39.18% examples, 352973 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:26,333 : INFO : EPOCH 1 - PROGRESS: at 42.03% examples, 353299 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:27,358 : INFO : EPOCH 1 - PROGRESS: at 44.89% examples, 353689 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:28,360 : INFO : EPOCH 1 - PROGRESS: at 47.67% examples, 354056 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:29,367 : INFO : EPOCH 1 - PROGRESS: at 50.34% examples, 353524 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:30,368 : INFO : EPOCH 1 - PROGRESS: at 53.27% examples, 354633 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:31,410 : INFO : EPOCH 1 - PROGRESS: at 56.11% examples, 354562 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:32,418 : INFO : EPOCH 1 - PROGRESS: at 58.79% examples, 354411 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:21:33,443 : INFO : EPOCH 1 - PROGRESS: at 61.70% examples, 354941 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:34,467 : INFO : EPOCH 1 - PROGRESS: at 64.44% examples, 354563 words/s, in_qsize 7, out_qsize 1\n",
            "2022-01-27 12:21:35,478 : INFO : EPOCH 1 - PROGRESS: at 67.18% examples, 354356 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:21:36,521 : INFO : EPOCH 1 - PROGRESS: at 70.10% examples, 354591 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:37,551 : INFO : EPOCH 1 - PROGRESS: at 72.89% examples, 354448 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:38,586 : INFO : EPOCH 1 - PROGRESS: at 75.70% examples, 354241 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:39,587 : INFO : EPOCH 1 - PROGRESS: at 78.43% examples, 354202 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:40,604 : INFO : EPOCH 1 - PROGRESS: at 81.32% examples, 354470 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:41,640 : INFO : EPOCH 1 - PROGRESS: at 84.18% examples, 354497 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:42,661 : INFO : EPOCH 1 - PROGRESS: at 86.92% examples, 354254 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:43,711 : INFO : EPOCH 1 - PROGRESS: at 89.80% examples, 354361 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:21:44,765 : INFO : EPOCH 1 - PROGRESS: at 92.73% examples, 354396 words/s, in_qsize 7, out_qsize 1\n",
            "2022-01-27 12:21:45,769 : INFO : EPOCH 1 - PROGRESS: at 95.71% examples, 354965 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:46,797 : INFO : EPOCH 1 - PROGRESS: at 98.44% examples, 354868 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:47,306 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 12:21:47,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 12:21:47,327 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 12:21:47,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 12:21:47,344 : INFO : EPOCH - 1 : training on 17798269 raw words (12873303 effective words) took 36.3s, 355072 effective words/s\n",
            "2022-01-27 12:21:48,373 : INFO : EPOCH 2 - PROGRESS: at 2.68% examples, 345780 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:21:49,364 : INFO : EPOCH 2 - PROGRESS: at 5.42% examples, 349160 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:50,394 : INFO : EPOCH 2 - PROGRESS: at 8.33% examples, 351804 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:51,418 : INFO : EPOCH 2 - PROGRESS: at 11.14% examples, 352057 words/s, in_qsize 8, out_qsize 2\n",
            "2022-01-27 12:21:52,434 : INFO : EPOCH 2 - PROGRESS: at 13.99% examples, 352875 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:21:53,434 : INFO : EPOCH 2 - PROGRESS: at 16.95% examples, 356573 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:54,441 : INFO : EPOCH 2 - PROGRESS: at 19.60% examples, 354068 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:21:55,434 : INFO : EPOCH 2 - PROGRESS: at 22.43% examples, 354983 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:21:56,456 : INFO : EPOCH 2 - PROGRESS: at 25.28% examples, 355583 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:57,462 : INFO : EPOCH 2 - PROGRESS: at 28.03% examples, 355206 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:58,486 : INFO : EPOCH 2 - PROGRESS: at 30.80% examples, 354265 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:21:59,512 : INFO : EPOCH 2 - PROGRESS: at 33.72% examples, 354598 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:00,557 : INFO : EPOCH 2 - PROGRESS: at 36.62% examples, 354993 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:01,560 : INFO : EPOCH 2 - PROGRESS: at 39.42% examples, 355346 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:02,567 : INFO : EPOCH 2 - PROGRESS: at 42.19% examples, 355558 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:03,574 : INFO : EPOCH 2 - PROGRESS: at 45.01% examples, 355743 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:04,608 : INFO : EPOCH 2 - PROGRESS: at 47.84% examples, 355734 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:05,618 : INFO : EPOCH 2 - PROGRESS: at 50.57% examples, 355453 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:06,646 : INFO : EPOCH 2 - PROGRESS: at 53.56% examples, 356339 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:07,692 : INFO : EPOCH 2 - PROGRESS: at 56.26% examples, 355390 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:08,709 : INFO : EPOCH 2 - PROGRESS: at 59.00% examples, 355462 words/s, in_qsize 8, out_qsize 2\n",
            "2022-01-27 12:22:09,711 : INFO : EPOCH 2 - PROGRESS: at 61.87% examples, 356001 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:10,710 : INFO : EPOCH 2 - PROGRESS: at 64.62% examples, 355833 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:11,718 : INFO : EPOCH 2 - PROGRESS: at 67.46% examples, 356227 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:22:12,729 : INFO : EPOCH 2 - PROGRESS: at 70.16% examples, 355712 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:13,739 : INFO : EPOCH 2 - PROGRESS: at 73.00% examples, 356072 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:14,767 : INFO : EPOCH 2 - PROGRESS: at 75.82% examples, 355978 words/s, in_qsize 7, out_qsize 1\n",
            "2022-01-27 12:22:15,780 : INFO : EPOCH 2 - PROGRESS: at 78.67% examples, 356168 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:16,826 : INFO : EPOCH 2 - PROGRESS: at 81.53% examples, 356004 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:17,869 : INFO : EPOCH 2 - PROGRESS: at 84.40% examples, 355917 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:18,912 : INFO : EPOCH 2 - PROGRESS: at 87.31% examples, 356041 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:19,958 : INFO : EPOCH 2 - PROGRESS: at 90.19% examples, 356149 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:20,973 : INFO : EPOCH 2 - PROGRESS: at 93.01% examples, 356141 words/s, in_qsize 7, out_qsize 1\n",
            "2022-01-27 12:22:21,996 : INFO : EPOCH 2 - PROGRESS: at 95.91% examples, 356243 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:23,019 : INFO : EPOCH 2 - PROGRESS: at 98.77% examples, 356543 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:23,384 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 12:22:23,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 12:22:23,454 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 12:22:23,462 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 12:22:23,464 : INFO : EPOCH - 2 : training on 17798269 raw words (12873079 effective words) took 36.1s, 356533 effective words/s\n",
            "2022-01-27 12:22:24,496 : INFO : EPOCH 3 - PROGRESS: at 2.62% examples, 335480 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:25,513 : INFO : EPOCH 3 - PROGRESS: at 5.53% examples, 352338 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:22:26,530 : INFO : EPOCH 3 - PROGRESS: at 8.39% examples, 352990 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:27,547 : INFO : EPOCH 3 - PROGRESS: at 11.14% examples, 351761 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:28,550 : INFO : EPOCH 3 - PROGRESS: at 13.94% examples, 352118 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:29,618 : INFO : EPOCH 3 - PROGRESS: at 16.89% examples, 351979 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:30,669 : INFO : EPOCH 3 - PROGRESS: at 19.88% examples, 353676 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:31,677 : INFO : EPOCH 3 - PROGRESS: at 22.76% examples, 355164 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:32,702 : INFO : EPOCH 3 - PROGRESS: at 25.57% examples, 354813 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:33,710 : INFO : EPOCH 3 - PROGRESS: at 28.43% examples, 355783 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:22:34,713 : INFO : EPOCH 3 - PROGRESS: at 31.26% examples, 356148 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:35,769 : INFO : EPOCH 3 - PROGRESS: at 34.22% examples, 356027 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:36,817 : INFO : EPOCH 3 - PROGRESS: at 37.11% examples, 356211 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:22:37,847 : INFO : EPOCH 3 - PROGRESS: at 39.96% examples, 356284 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:38,876 : INFO : EPOCH 3 - PROGRESS: at 42.74% examples, 355939 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:22:39,898 : INFO : EPOCH 3 - PROGRESS: at 45.55% examples, 355758 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:40,907 : INFO : EPOCH 3 - PROGRESS: at 48.43% examples, 356692 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:41,913 : INFO : EPOCH 3 - PROGRESS: at 51.25% examples, 356816 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:42,926 : INFO : EPOCH 3 - PROGRESS: at 54.05% examples, 356813 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:43,928 : INFO : EPOCH 3 - PROGRESS: at 56.88% examples, 357310 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:44,941 : INFO : EPOCH 3 - PROGRESS: at 59.55% examples, 356942 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:45,960 : INFO : EPOCH 3 - PROGRESS: at 62.43% examples, 357314 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:22:46,960 : INFO : EPOCH 3 - PROGRESS: at 65.23% examples, 357304 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:47,974 : INFO : EPOCH 3 - PROGRESS: at 68.15% examples, 357826 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:49,019 : INFO : EPOCH 3 - PROGRESS: at 70.94% examples, 357350 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 12:22:50,057 : INFO : EPOCH 3 - PROGRESS: at 73.85% examples, 357527 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:51,083 : INFO : EPOCH 3 - PROGRESS: at 76.77% examples, 357814 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:52,118 : INFO : EPOCH 3 - PROGRESS: at 79.57% examples, 357487 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:53,138 : INFO : EPOCH 3 - PROGRESS: at 82.38% examples, 357366 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:54,146 : INFO : EPOCH 3 - PROGRESS: at 85.18% examples, 357393 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:22:55,159 : INFO : EPOCH 3 - PROGRESS: at 88.02% examples, 357582 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:56,183 : INFO : EPOCH 3 - PROGRESS: at 90.82% examples, 357419 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:22:57,184 : INFO : EPOCH 3 - PROGRESS: at 93.56% examples, 357298 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:58,192 : INFO : EPOCH 3 - PROGRESS: at 96.41% examples, 357338 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:59,266 : INFO : EPOCH 3 - PROGRESS: at 99.27% examples, 357109 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:22:59,452 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 12:22:59,462 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 12:22:59,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 12:22:59,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 12:22:59,494 : INFO : EPOCH - 3 : training on 17798269 raw words (12871595 effective words) took 36.0s, 357437 effective words/s\n",
            "2022-01-27 12:23:00,520 : INFO : EPOCH 4 - PROGRESS: at 2.74% examples, 349086 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:01,520 : INFO : EPOCH 4 - PROGRESS: at 5.54% examples, 354953 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:02,538 : INFO : EPOCH 4 - PROGRESS: at 8.50% examples, 359497 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:03,558 : INFO : EPOCH 4 - PROGRESS: at 11.38% examples, 359930 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:04,628 : INFO : EPOCH 4 - PROGRESS: at 14.34% examples, 358194 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:05,639 : INFO : EPOCH 4 - PROGRESS: at 17.23% examples, 359215 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:06,642 : INFO : EPOCH 4 - PROGRESS: at 20.11% examples, 360258 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:07,682 : INFO : EPOCH 4 - PROGRESS: at 22.93% examples, 358629 words/s, in_qsize 7, out_qsize 1\n",
            "2022-01-27 12:23:08,694 : INFO : EPOCH 4 - PROGRESS: at 25.80% examples, 359116 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:09,734 : INFO : EPOCH 4 - PROGRESS: at 28.59% examples, 357897 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:10,770 : INFO : EPOCH 4 - PROGRESS: at 31.56% examples, 358295 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:11,782 : INFO : EPOCH 4 - PROGRESS: at 34.39% examples, 358103 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:12,789 : INFO : EPOCH 4 - PROGRESS: at 37.11% examples, 357586 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:13,795 : INFO : EPOCH 4 - PROGRESS: at 39.91% examples, 357645 words/s, in_qsize 8, out_qsize 2\n",
            "2022-01-27 12:23:14,831 : INFO : EPOCH 4 - PROGRESS: at 42.75% examples, 357508 words/s, in_qsize 4, out_qsize 3\n",
            "2022-01-27 12:23:15,836 : INFO : EPOCH 4 - PROGRESS: at 45.71% examples, 358936 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:16,847 : INFO : EPOCH 4 - PROGRESS: at 48.39% examples, 358000 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 12:23:17,874 : INFO : EPOCH 4 - PROGRESS: at 51.31% examples, 358449 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:18,878 : INFO : EPOCH 4 - PROGRESS: at 54.10% examples, 358514 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:19,897 : INFO : EPOCH 4 - PROGRESS: at 56.93% examples, 358613 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:20,903 : INFO : EPOCH 4 - PROGRESS: at 59.67% examples, 358628 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:21,923 : INFO : EPOCH 4 - PROGRESS: at 62.54% examples, 358738 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:22,959 : INFO : EPOCH 4 - PROGRESS: at 65.40% examples, 358614 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:23,963 : INFO : EPOCH 4 - PROGRESS: at 68.26% examples, 358951 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:24,966 : INFO : EPOCH 4 - PROGRESS: at 70.93% examples, 358420 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:25,985 : INFO : EPOCH 4 - PROGRESS: at 73.85% examples, 358823 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:27,007 : INFO : EPOCH 4 - PROGRESS: at 76.66% examples, 358608 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:28,008 : INFO : EPOCH 4 - PROGRESS: at 79.34% examples, 358178 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:29,054 : INFO : EPOCH 4 - PROGRESS: at 82.15% examples, 357701 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:30,058 : INFO : EPOCH 4 - PROGRESS: at 84.94% examples, 357761 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:31,063 : INFO : EPOCH 4 - PROGRESS: at 87.75% examples, 357804 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:32,067 : INFO : EPOCH 4 - PROGRESS: at 90.47% examples, 357629 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:33,114 : INFO : EPOCH 4 - PROGRESS: at 93.40% examples, 357666 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:34,115 : INFO : EPOCH 4 - PROGRESS: at 96.36% examples, 358184 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:35,165 : INFO : EPOCH 4 - PROGRESS: at 99.11% examples, 357752 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:35,386 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 12:23:35,408 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 12:23:35,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 12:23:35,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 12:23:35,434 : INFO : EPOCH - 4 : training on 17798269 raw words (12872415 effective words) took 35.9s, 358277 effective words/s\n",
            "2022-01-27 12:23:36,471 : INFO : EPOCH 5 - PROGRESS: at 2.68% examples, 343818 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:37,469 : INFO : EPOCH 5 - PROGRESS: at 5.48% examples, 350635 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:38,503 : INFO : EPOCH 5 - PROGRESS: at 8.39% examples, 352229 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:39,523 : INFO : EPOCH 5 - PROGRESS: at 11.32% examples, 356226 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:40,536 : INFO : EPOCH 5 - PROGRESS: at 14.11% examples, 354945 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:41,545 : INFO : EPOCH 5 - PROGRESS: at 17.00% examples, 356627 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:42,575 : INFO : EPOCH 5 - PROGRESS: at 19.81% examples, 355732 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:43,648 : INFO : EPOCH 5 - PROGRESS: at 22.82% examples, 355868 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 12:23:44,654 : INFO : EPOCH 5 - PROGRESS: at 25.69% examples, 357030 words/s, in_qsize 7, out_qsize 1\n",
            "2022-01-27 12:23:45,689 : INFO : EPOCH 5 - PROGRESS: at 28.60% examples, 357542 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:46,712 : INFO : EPOCH 5 - PROGRESS: at 31.43% examples, 357100 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:23:47,744 : INFO : EPOCH 5 - PROGRESS: at 34.27% examples, 356418 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:48,754 : INFO : EPOCH 5 - PROGRESS: at 37.06% examples, 356447 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:49,767 : INFO : EPOCH 5 - PROGRESS: at 39.86% examples, 356470 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:50,784 : INFO : EPOCH 5 - PROGRESS: at 42.69% examples, 356853 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:51,798 : INFO : EPOCH 5 - PROGRESS: at 45.41% examples, 355919 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:52,801 : INFO : EPOCH 5 - PROGRESS: at 48.22% examples, 356561 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 12:23:53,835 : INFO : EPOCH 5 - PROGRESS: at 51.01% examples, 356151 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:54,836 : INFO : EPOCH 5 - PROGRESS: at 53.83% examples, 356388 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:55,842 : INFO : EPOCH 5 - PROGRESS: at 56.66% examples, 356843 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:56,846 : INFO : EPOCH 5 - PROGRESS: at 59.39% examples, 356976 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:23:57,874 : INFO : EPOCH 5 - PROGRESS: at 62.13% examples, 356374 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:23:58,917 : INFO : EPOCH 5 - PROGRESS: at 65.06% examples, 356537 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 12:23:59,917 : INFO : EPOCH 5 - PROGRESS: at 67.86% examples, 356715 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 12:24:00,943 : INFO : EPOCH 5 - PROGRESS: at 70.71% examples, 356937 words/s, in_qsize 8, out_qsize 2\n",
            "2022-01-27 12:24:01,981 : INFO : EPOCH 5 - PROGRESS: at 73.56% examples, 356997 words/s, in_qsize 7, out_qsize 3\n",
            "2022-01-27 12:24:02,993 : INFO : EPOCH 5 - PROGRESS: at 76.50% examples, 357248 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:24:04,009 : INFO : EPOCH 5 - PROGRESS: at 79.35% examples, 357423 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:24:05,041 : INFO : EPOCH 5 - PROGRESS: at 82.15% examples, 357139 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 12:24:06,064 : INFO : EPOCH 5 - PROGRESS: at 85.12% examples, 357718 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:24:07,152 : INFO : EPOCH 5 - PROGRESS: at 87.96% examples, 357059 words/s, in_qsize 8, out_qsize 1\n",
            "2022-01-27 12:24:08,171 : INFO : EPOCH 5 - PROGRESS: at 90.82% examples, 357179 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 12:24:09,193 : INFO : EPOCH 5 - PROGRESS: at 93.63% examples, 357077 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:24:10,215 : INFO : EPOCH 5 - PROGRESS: at 96.53% examples, 357183 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:24:11,249 : INFO : EPOCH 5 - PROGRESS: at 99.33% examples, 357170 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 12:24:11,392 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 12:24:11,425 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 12:24:11,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 12:24:11,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 12:24:11,439 : INFO : EPOCH - 5 : training on 17798269 raw words (12872314 effective words) took 36.0s, 357669 effective words/s\n",
            "2022-01-27 12:24:11,441 : INFO : training on a 88991345 raw words (64362706 effective words) took 180.4s, 356850 effective words/s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7fe16f887b50>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 완료 되면 필요없는 메모리를 unload 시킨다.\n",
        "model.init_sims(replace=True)\n",
        "\n",
        "model_name = '300features_40minwords_10text'\n",
        "# model_name = '300features_50minwords_20text'\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESlJxpx9OCZS",
        "outputId": "b4c43c16-2bc3-4b06-8856-4c18d731a85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 12:25:41,716 : INFO : precomputing L2-norms of word weight vectors\n",
            "2022-01-27 12:25:41,833 : INFO : saving Word2Vec object under 300features_40minwords_10text, separately None\n",
            "2022-01-27 12:25:41,836 : INFO : not storing attribute vectors_norm\n",
            "2022-01-27 12:25:41,839 : INFO : not storing attribute cum_table\n",
            "2022-01-27 12:25:42,232 : INFO : saved 300features_40minwords_10text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사도가 없는 단어 추출\n",
        "model.wv.doesnt_match('man woman child kitchen'.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "4Rcb4oLPOCbT",
        "outputId": "18a67353-e6f2-424c-e5b5-031d13f053db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'kitchen'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7xxGKyBVW9p",
        "outputId": "3b9f8ed6-88ce-4ec4-eee8-2a2a24ee7e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['man', 'woman', 'child', 'kitchen']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.doesnt_match(\"france england germany berlin\".split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "JIGSutNQOCdi",
        "outputId": "561d94f5-305c-4431-f5ce-ca716ecf4d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 12:25:55,744 : WARNING : vectors for words {'france', 'germany'} are not present in the model, ignoring these words\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'berlin'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 유사한 단어를 추출\n",
        "model.wv.most_similar(\"man\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a3eyKwtOCfn",
        "outputId": "875f0fe3-5475-42be-f756-3bdd5f0e920e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.6337493062019348),\n",
              " ('millionair', 0.5218256115913391),\n",
              " ('lad', 0.505902886390686),\n",
              " ('businessman', 0.5051427483558655),\n",
              " ('ladi', 0.4979287385940552),\n",
              " ('widow', 0.47199350595474243),\n",
              " ('men', 0.4599936902523041),\n",
              " ('farmer', 0.4585924744606018),\n",
              " ('loner', 0.4553702175617218),\n",
              " ('gunman', 0.45320284366607666)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sw5giAdHOChh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DnsOlW_bICSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYMMz1nfICWM",
        "outputId": "90fb8076-d1b1-434a-d80c-78e65ddabf8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,823 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:17 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [76.0 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,954 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,242 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [771 kB]\n",
            "Get:21 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [872 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,517 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [738 kB]\n",
            "Get:26 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,463 kB]\n",
            "Fetched 14.7 MB in 4s (4,028 kB/s)\n",
            "Reading package lists...\n",
            "Collecting JPype1\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1) (3.10.0.2)\n",
            "Installing collected packages: JPype1\n",
            "Successfully installed JPype1-1.3.0\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: konlpy\n",
            "Successfully installed konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "ZxUxiYpUICe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27R-JtSgICkm",
        "outputId": "ef01bce4-986b-42e6-8c61-a29f03a1cdb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings.txt', <http.client.HTTPMessage at 0x7fe16decad10>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_table('ratings.txt')"
      ],
      "metadata": {
        "id": "LH1eQMPPICtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nwzipNsCheAS",
        "outputId": "e40a837d-5837-4d93-c66b-720c0945ec3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3cfd7194-1739-4cf9-8737-9b448e005cdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cfd7194-1739-4cf9-8737-9b448e005cdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cfd7194-1739-4cf9-8737-9b448e005cdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cfd7194-1739-4cf9-8737-9b448e005cdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBDWkeMpheC3",
        "outputId": "e2d00f34-53e3-4ec2-f238-833721ac02ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 12:32:46,513 : INFO : NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리\n",
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
      ],
      "metadata": {
        "id": "vJSVpjVDheHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 정의\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "# 형태소 분석기 OKT를 사용한 토큰화 작업 (다소 시간 소요)\n",
        "okt = Okt()\n",
        "\n",
        "tokenized_data = []\n",
        "for sentence in (train_data['document']):\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화 # 텍스트를 형태소 단위로 나눈다.\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    tokenized_data.append(stopwords_removed_sentence)"
      ],
      "metadata": {
        "id": "IXkXaDODheJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "st5rSOqniwAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('리뷰의 최대 길이 :',max(len(review) for review in tokenized_data))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
        "plt.hist([len(review) for review in tokenized_data], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Vutyapr7iwHy",
        "outputId": "3f61bcd1-e796-4565-e7c0-3b48556e56f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 72\n",
            "리뷰의 평균 길이 : 10.716703668146726\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Al-ZXfn2iwMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(sentences = tokenized_data, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvZ6JGQbiwPg",
        "outputId": "4424263c-529b-4c82-d1e3-98fe698b23a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 13:14:13,845 : INFO : collecting all words and their counts\n",
            "2022-01-27 13:14:13,849 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-01-27 13:14:13,892 : INFO : PROGRESS: at sentence #10000, processed 103893 words, keeping 11534 word types\n",
            "2022-01-27 13:14:13,931 : INFO : PROGRESS: at sentence #20000, processed 210455 words, keeping 16574 word types\n",
            "2022-01-27 13:14:13,970 : INFO : PROGRESS: at sentence #30000, processed 314404 words, keeping 20052 word types\n",
            "2022-01-27 13:14:14,012 : INFO : PROGRESS: at sentence #40000, processed 418553 words, keeping 22857 word types\n",
            "2022-01-27 13:14:14,054 : INFO : PROGRESS: at sentence #50000, processed 522738 words, keeping 25403 word types\n",
            "2022-01-27 13:14:14,097 : INFO : PROGRESS: at sentence #60000, processed 627916 words, keeping 27650 word types\n",
            "2022-01-27 13:14:14,140 : INFO : PROGRESS: at sentence #70000, processed 733008 words, keeping 29597 word types\n",
            "2022-01-27 13:14:14,185 : INFO : PROGRESS: at sentence #80000, processed 838763 words, keeping 31460 word types\n",
            "2022-01-27 13:14:14,228 : INFO : PROGRESS: at sentence #90000, processed 942769 words, keeping 33131 word types\n",
            "2022-01-27 13:14:14,276 : INFO : PROGRESS: at sentence #100000, processed 1046849 words, keeping 34733 word types\n",
            "2022-01-27 13:14:14,329 : INFO : PROGRESS: at sentence #110000, processed 1155519 words, keeping 36885 word types\n",
            "2022-01-27 13:14:14,379 : INFO : PROGRESS: at sentence #120000, processed 1265970 words, keeping 38790 word types\n",
            "2022-01-27 13:14:14,429 : INFO : PROGRESS: at sentence #130000, processed 1376828 words, keeping 40443 word types\n",
            "2022-01-27 13:14:14,481 : INFO : PROGRESS: at sentence #140000, processed 1487661 words, keeping 41986 word types\n",
            "2022-01-27 13:14:14,525 : INFO : PROGRESS: at sentence #150000, processed 1598032 words, keeping 43455 word types\n",
            "2022-01-27 13:14:14,585 : INFO : PROGRESS: at sentence #160000, processed 1706938 words, keeping 44788 word types\n",
            "2022-01-27 13:14:14,630 : INFO : PROGRESS: at sentence #170000, processed 1815122 words, keeping 46033 word types\n",
            "2022-01-27 13:14:14,678 : INFO : PROGRESS: at sentence #180000, processed 1923181 words, keeping 47272 word types\n",
            "2022-01-27 13:14:14,725 : INFO : PROGRESS: at sentence #190000, processed 2033212 words, keeping 48465 word types\n",
            "2022-01-27 13:14:14,767 : INFO : collected 49645 word types from a corpus of 2143255 raw words and 199992 sentences\n",
            "2022-01-27 13:14:14,769 : INFO : Loading a fresh vocabulary\n",
            "2022-01-27 13:14:14,833 : INFO : effective_min_count=5 retains 16477 unique words (33% of original 49645, drops 33168)\n",
            "2022-01-27 13:14:14,835 : INFO : effective_min_count=5 leaves 2090100 word corpus (97% of original 2143255, drops 53155)\n",
            "2022-01-27 13:14:14,903 : INFO : deleting the raw counts dictionary of 49645 items\n",
            "2022-01-27 13:14:14,909 : INFO : sample=0.001 downsamples 52 most-common words\n",
            "2022-01-27 13:14:14,911 : INFO : downsampling leaves estimated 1839493 word corpus (88.0% of prior 2090100)\n",
            "2022-01-27 13:14:14,980 : INFO : estimated required memory for 16477 words and 100 dimensions: 21420100 bytes\n",
            "2022-01-27 13:14:14,982 : INFO : resetting layer weights\n",
            "2022-01-27 13:14:18,662 : INFO : training model with 4 workers on 16477 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2022-01-27 13:14:19,678 : INFO : EPOCH 1 - PROGRESS: at 29.11% examples, 516872 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:20,682 : INFO : EPOCH 1 - PROGRESS: at 57.91% examples, 517689 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:21,705 : INFO : EPOCH 1 - PROGRESS: at 86.13% examples, 520293 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:22,135 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 13:14:22,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 13:14:22,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 13:14:22,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 13:14:22,168 : INFO : EPOCH - 1 : training on 2143255 raw words (1839634 effective words) took 3.5s, 526868 effective words/s\n",
            "2022-01-27 13:14:23,199 : INFO : EPOCH 2 - PROGRESS: at 29.11% examples, 507876 words/s, in_qsize 6, out_qsize 1\n",
            "2022-01-27 13:14:24,200 : INFO : EPOCH 2 - PROGRESS: at 58.80% examples, 522665 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:25,240 : INFO : EPOCH 2 - PROGRESS: at 87.48% examples, 523349 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:25,599 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 13:14:25,627 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 13:14:25,636 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 13:14:25,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 13:14:25,643 : INFO : EPOCH - 2 : training on 2143255 raw words (1839544 effective words) took 3.5s, 531315 effective words/s\n",
            "2022-01-27 13:14:26,671 : INFO : EPOCH 3 - PROGRESS: at 27.70% examples, 484752 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 13:14:27,689 : INFO : EPOCH 3 - PROGRESS: at 57.00% examples, 501826 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:28,693 : INFO : EPOCH 3 - PROGRESS: at 85.16% examples, 512971 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:29,193 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 13:14:29,198 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 13:14:29,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 13:14:29,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 13:14:29,210 : INFO : EPOCH - 3 : training on 2143255 raw words (1839377 effective words) took 3.6s, 517532 effective words/s\n",
            "2022-01-27 13:14:30,240 : INFO : EPOCH 4 - PROGRESS: at 28.64% examples, 501554 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 13:14:31,273 : INFO : EPOCH 4 - PROGRESS: at 59.69% examples, 523920 words/s, in_qsize 7, out_qsize 0\n",
            "2022-01-27 13:14:32,285 : INFO : EPOCH 4 - PROGRESS: at 88.85% examples, 531947 words/s, in_qsize 8, out_qsize 0\n",
            "2022-01-27 13:14:32,654 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 13:14:32,657 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 13:14:32,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 13:14:32,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 13:14:32,668 : INFO : EPOCH - 4 : training on 2143255 raw words (1839239 effective words) took 3.4s, 534435 effective words/s\n",
            "2022-01-27 13:14:33,735 : INFO : EPOCH 5 - PROGRESS: at 29.60% examples, 500207 words/s, in_qsize 8, out_qsize 2\n",
            "2022-01-27 13:14:34,763 : INFO : EPOCH 5 - PROGRESS: at 59.69% examples, 516090 words/s, in_qsize 5, out_qsize 2\n",
            "2022-01-27 13:14:35,764 : INFO : EPOCH 5 - PROGRESS: at 87.48% examples, 520015 words/s, in_qsize 8, out_qsize 3\n",
            "2022-01-27 13:14:36,144 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2022-01-27 13:14:36,154 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2022-01-27 13:14:36,160 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-01-27 13:14:36,162 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-01-27 13:14:36,163 : INFO : EPOCH - 5 : training on 2143255 raw words (1839481 effective words) took 3.5s, 528812 effective words/s\n",
            "2022-01-27 13:14:36,165 : INFO : training on a 10716275 raw words (9197275 effective words) took 17.5s, 525524 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wP6_Yw3viwR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xji-wtMiwUu",
        "outputId": "97df49ae-bc49-4cd9-d024-858b62aa26e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16477, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPZ2iIKHiwW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.most_similar(\"최민식\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6IhI3vQiwY5",
        "outputId": "ee5d9566-ca81-44cb-a389-042446ee2eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 13:15:10,742 : INFO : precomputing L2-norms of word weight vectors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('김명민', 0.8561480045318604), ('안성기', 0.8529692888259888), ('한석규', 0.8519237041473389), ('미스캐스팅', 0.8461310863494873), ('이정재', 0.841224193572998), ('최민수', 0.8379496335983276), ('신인', 0.8322809934616089), ('송강호', 0.8282245397567749), ('이주승', 0.8258365988731384), ('황정민', 0.8257161378860474)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJ7cQQLDiwba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/NPL/MyWord2vec.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Evng_dJheMJ",
        "outputId": "169a0361-88dc-426a-b2e1-be50d8205080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 13:17:16,774 : INFO : saving Word2Vec object under /content/drive/MyDrive/NPL/MyWord2vec.bin, separately None\n",
            "2022-01-27 13:17:16,779 : INFO : not storing attribute vectors_norm\n",
            "2022-01-27 13:17:16,781 : INFO : not storing attribute cum_table\n",
            "2022-01-27 13:17:17,162 : INFO : saved /content/drive/MyDrive/NPL/MyWord2vec.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, '/content/drive/MyDrive/NPL/MyWord2vec.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UU4RJ8jheOP",
        "outputId": "2d2aba22-e60c-49e3-fcda-da05e817b8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/NPL/MyWord2vec.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVZy_ch-heQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LCQzLIwStaER",
        "outputId": "33fa1178-266a-4514-9997-23eec0b111c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "',ㄱ'"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iD3jOrFUtaG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 나만의 word2vec"
      ],
      "metadata": {
        "id": "I5vH5BiVt_7I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULs6N2DUtaJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Bu527qTKtaNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0419d10-0439-4157-8f00-9c13a0b8705c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# 파일 불러보기\n",
        "loaded_model = joblib.load('/content/drive/MyDrive/NPL/MyWord2vec.pkl')\n"
      ],
      "metadata": {
        "id": "oGPAqKAoheS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FO9JS7YvzhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.wv.most_similar(positive=['르브론'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgcMYePRuE8Y",
        "outputId": "a7d2edce-51e1-437f-f7a8-a1f03b8a51b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('신발', 0.987055778503418),\n",
              " ('농구', 0.9814304113388062),\n",
              " ('조던', 0.9765362739562988),\n",
              " ('화', 0.9758518934249878),\n",
              " ('스니커', 0.9725878238677979),\n",
              " ('타격', 0.21992114186286926),\n",
              " ('삭발', 0.214054673910141),\n",
              " ('토이', 0.19997797906398773),\n",
              " ('류현진', 0.19388997554779053),\n",
              " ('양반', 0.19026854634284973)]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "li = [\n",
        "     '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "       '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "       '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "       '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "       '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "       '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "       '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "       '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커','농구화 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '신발 조던 르브론 농구 스니커',\n",
        "      '조던 르브론 농구 스니커',\n",
        "]"
      ],
      "metadata": {
        "id": "acuJiVFWzhM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "def makeToken(li):\n",
        "  stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "  # 형태소 분석기 OKT를 사용한 토큰화 작업 (다소 시간 소요)\n",
        "  okt = Okt()\n",
        "\n",
        "  tokenized_data = []\n",
        "  for sentence in li:\n",
        "      tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화 # 텍스트를 형태소 단위로 나눈다.\n",
        "      stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "      tokenized_data.append(stopwords_removed_sentence)\n",
        "\n",
        "  return tokenized_data\n",
        "\n",
        "\n",
        "def LetsTrain(model,tokenized_data):\n",
        "  # model = Word2Vec(sentences = tokenized_data, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
        "  # model.train(sentences,total_examples=model.corpus_count,epochs=model.iter)\n",
        "  model_2 = Word2Vec(size=300, min_count=1) # 새로운 단어를 학습할 모델\n",
        "  model_2.build_vocab(tokenized_data) # 단어 추가\n",
        "  model_2.build_vocab([list(model.wv.vocab.keys())], update=True) # 기존 모델과 합침\n",
        "  model_2.train(tokenized_data, total_examples= model_2.corpus_count, epochs=model_2.iter) # 훈련\n",
        "\n",
        "  return model_2\n"
      ],
      "metadata": {
        "id": "WothUzlxheXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = makeToken(li)\n",
        "token[:10], len(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9WbqoLH4-p_",
        "outputId": "b4303a05-6f8e-45f0-f080-bd6ec116142f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커'],\n",
              "  ['신발', '조던', '르브론', '농구', '스니커']],\n",
              " 112)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plzModel = LetsTrain(loaded_model,token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqdkp7P-tbDS",
        "outputId": "43356455-f1f5-4ea0-d366-4c71748a53fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plzModel.wv.most_similar(positive=['감동'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKebBlFmtbHi",
        "outputId": "9456d45d-2841-4119-e5c8-9e4e7f4e36a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('카리스마', 0.23418517410755157),\n",
              " ('표시', 0.21633443236351013),\n",
              " ('찍지마라', 0.20859844982624054),\n",
              " ('알리샤', 0.20551899075508118),\n",
              " ('만족스럽다', 0.20415033400058746),\n",
              " ('점준', 0.20380525290966034),\n",
              " ('따라다니다', 0.20309239625930786),\n",
              " ('사시', 0.20063839852809906),\n",
              " ('어투', 0.19270800054073334),\n",
              " ('수탈', 0.19101575016975403)]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(loaded_model.wv.vocab), len(plzModel.wv.vocab) # 들어간 단어수 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2x_EymSbtU4",
        "outputId": "f586278e-7665-4950-c2a9-b3af68ca2052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16477, 16479)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장\n",
        "import joblib\n",
        "joblib.dump(plzModel, '/content/drive/MyDrive/NPL/MyWord2vec.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC-ydKTOs_IC",
        "outputId": "5b42ff7f-ee02-403c-eccc-583c2ce17249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/NPL/MyWord2vec.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mOAQ9Fd8vVZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시행착오"
      ],
      "metadata": {
        "id": "8mU_L5o5vWEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "# 파일 불러보기\n",
        "# loaded_model = joblib.load('/content/drive/MyDrive/NPL/MyWord2vec.pkl')\n",
        "modelPlz = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/NPL/MyKoModel', binary=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "7t0OYWPbcGVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(modelPlz.wv.vocab), len(model_2.wv.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH_Duba5p1Uf",
        "outputId": "20d75b7b-7451-4585-f7e5-b2f4b2590769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16477, 16479)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Word2Vec(size=300, min_count=1) # 새로운 단어를 학습할 모델\n",
        "model_2.build_vocab(token) # 단어 추가\n",
        "model_2.build_vocab([list(loaded_model.wv.vocab.keys())], update=True) # 기존 모델과 합침"
      ],
      "metadata": {
        "id": "V64uhZTwdoSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2.build_vocab([list(loaded_model.wv.vocab.keys())], update=True)\n",
        "# model_2.intersect_word2vec_format(\"/content/drive/MyDrive/NPL/MyKoModel\", binary=False)\n",
        "#   Merge the input-hidden weight matrix from the original word2vec-tool format given, where it intersects with the current vocabulary.\n",
        "#   (No words are added to the existing vocabulary, but intersecting words adopt the file’s weights, and non-intersecting words are left alone.)\n",
        "model_2.train(token, total_examples= model_2.corpus_count, epochs=model_2.iter)\n",
        "\n",
        "# 안됨.. 인코딩문제??\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "faevGlNrdoVT",
        "outputId": "800511e7-1528-4d9a-d028-82d43f4a92ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-633c5b9c3209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/NPL/MyKoModel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#   Merge the input-hidden weight matrix from the original word2vec-tool format given, where it intersects with the current vocabulary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#   (No words are added to the existing vocabulary, but intersecting words adopt the file’s weights, and non-intersecting words are left alone.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mintersect_word2vec_format\u001b[0;34m(self, fname, lockf, binary, encoding, unicode_errors)\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"incompatible vector size %d in file %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m                 \u001b[0;31m# TOCONSIDER: maybe mismatched vectors still useful enough to merge (truncating/padding)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: incompatible vector size 100 in file /content/drive/MyDrive/NPL/MyKoModel"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.wv.most_similar('르브론') # 단어 등록 완료확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LSY0rFndoXh",
        "outputId": "2932aace-4260-4c83-9728-0da0dd13407c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('썩을', 0.20377802848815918), ('서브', 0.1986670047044754), ('재임', 0.19817489385604858), ('느끼하다', 0.1948268711566925), ('매도', 0.1903342604637146), ('타이어', 0.18985819816589355), ('잘맞다', 0.1872764229774475), ('오래', 0.1867975890636444), ('땅콩', 0.1866961419582367), ('뿐이다', 0.18474434316158295)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.train(token, total_examples= model_2.corpus_count, epochs=model_2.iter) # 훈련"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1GvA88MdoZp",
        "outputId": "88198a7d-8079-488f-e6dc-269bf37cbf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3769, 4905)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.wv.most_similar('르브론') # 성공!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VkCIYCvrxE6",
        "outputId": "8c9926c5-a8ad-44c4-efee-ff3813e9c324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('농구', 0.9973356127738953),\n",
              " ('신발', 0.9962156414985657),\n",
              " ('사다', 0.9949896335601807),\n",
              " ('사람', 0.9627845287322998),\n",
              " ('화', 0.9470525979995728),\n",
              " ('싶다', 0.9204604625701904),\n",
              " ('나', 0.8815547823905945),\n",
              " ('보다', 0.8606065511703491),\n",
              " ('발사', 0.8594789505004883),\n",
              " ('신', 0.8580775856971741)]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPNDgAbXr3Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L3lpR8IUr3fk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}